{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYZbRsFoPjbY"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda *args, **kwargs: \"UTF-8\"\n",
        "!pip install transformers==4.28.0\n",
        "!pip install --upgrade accelerate\n",
        "!pip install jellyfish"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import csv\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "Tse4ydINPmfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text preprocessing\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('vader_lexicon')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Remove punctuation and convert to lowercase\n",
        "    text = ''.join([c for c in text if c.isalpha() or c.isspace()]).lower()\n",
        "    # Tokenize the text\n",
        "    tokens = word_tokenize(text)\n",
        "    # Remove stop words and perform stemming\n",
        "    tokens = [stemmer.stem(token) for token in tokens if token not in stop_words]\n",
        "    # Join the tokens back into a string\n",
        "    preprocessed_text = ' '.join(tokens)\n",
        "    return preprocessed_text"
      ],
      "metadata": {
        "id": "YiWr2J-DPpgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "\n",
        "# Read data from CSV file\n",
        "data = []\n",
        "with open('train_data_final.csv', 'r', encoding='utf-8') as file:\n",
        "    reader = csv.reader(file)\n",
        "    for row in reader:\n",
        "        question = preprocess_text(row[0])\n",
        "        answer = preprocess_text(row[1])\n",
        "        data.append((question, answer))\n",
        "\n",
        "# Shuffle the indices\n",
        "indices = list(range(len(data)))\n",
        "random.shuffle(indices)\n",
        "\n",
        "# Shuffle the dataset while preserving the correspondence between questions and answers\n",
        "shuffled_data = [data[i] for i in indices]\n",
        "\n",
        "# Prepare the training dataset\n",
        "train_dataset = TextDataset(\n",
        "    tokenizer=tokenizer,\n",
        "    file_path='train_data_final.csv',\n",
        "    block_size=128  # Adjust the block size as per your data\n",
        ")\n",
        "\n",
        "\n",
        "# Define your training arguments as before\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./output',\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=15,\n",
        "    per_device_train_batch_size=4,\n",
        "    save_steps=10_000,\n",
        "    save_total_limit=2,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.02,\n",
        "    warmup_steps=500,\n",
        "    logging_dir='./logs'\n",
        ")\n",
        "\n",
        "# Initialize your Trainer as before\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False),\n",
        "    train_dataset=train_dataset\n",
        ")\n",
        "\n",
        "\n",
        "# Initialize lists to store training loss and learning rate\n",
        "train_loss_list = []\n",
        "learning_rate_list = []\n",
        "\n",
        "# Override the compute_loss method to track training loss and learning rate\n",
        "def compute_loss(model, inputs, return_outputs=False):\n",
        "    outputs = model(**inputs)\n",
        "    loss = outputs.loss\n",
        "    train_loss_list.append(loss.item())\n",
        "    learning_rate_list.append(trainer.optimizer.param_groups[0]['lr'])  # Get current learning rate from optimizer\n",
        "    return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# Patch the Trainer to use the custom compute_loss method\n",
        "trainer.compute_loss = compute_loss\n",
        "\n",
        "# Start the fine-tuning\n",
        "trainer.train()\n",
        "\n",
        "# Save the fine-tuned model\n",
        "trainer.save_model(\"./output_model\")"
      ],
      "metadata": {
        "id": "ALiyv_4HPsHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training loss\n",
        "plt.plot(range(len(train_loss_list)), train_loss_list, label='Training Loss')\n",
        "plt.xlabel('Training Steps')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss over Steps')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot learning rate\n",
        "plt.plot(range(len(learning_rate_list)), learning_rate_list, label='Learning Rate')\n",
        "plt.xlabel('Training Steps')\n",
        "plt.ylabel('Learning Rate')\n",
        "plt.title('Learning Rate over Steps')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "z6cdrKhjPvHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "greetings = {\n",
        "    \"hi\": \"Hello!\",\n",
        "    \"hello\": \"Hi there!\",\n",
        "    \"hey\": \"Hey, how can I assist you?\",\n",
        "    \"greetings\": \"Greetings! How may I help you?\",\n",
        "    \"how are you\": \"I'm good, thank you! How about you?\",\n",
        "    \"what's up\": \"Not much, just here to assist you!\",\n",
        "    \"good morning\": \"Good morning! How can I assist you today?\",\n",
        "    \"good afternoon\": \"Good afternoon! How may I help you?\",\n",
        "    \"good evening\": \"Good evening! How can I assist you today?\",\n",
        "    \"howdy\": \"Howdy! What can I do for you?\",\n",
        "    \"nice to meet you\": \"Nice to meet you too!\",\n",
        "    \"what's going on\": \"Just here to help. How can I assist you?\",\n",
        "    \"hey there\": \"Hello! How can I assist you today?\",\n",
        "    \"long time no see\": \"Yes, it has been a while! How may I assist you?\",\n",
        "    \"what can you do\": \"I can answer your questions and assist with information. How can I help you?\",\n",
        "    \"it's nice to see you\": \"Thank you! How can I assist you today?\",\n",
        "    \"what's happening\": \"Not much, just here to assist you!\",\n",
        "    \"how's it going\": \"I'm doing well. How can I assist you?\",\n",
        "    \"good to see you\": \"Good to see you too! How may I assist you?\",\n",
        "    \"hey buddy\": \"Hey! What can I do for you today?\",\n",
        "    \"how have you been\": \"I've been good. How about you?\",\n",
        "    \"good to meet you\": \"Likewise! How can I assist you?\",\n",
        "    \"what's new\": \"Not much, just here to assist you!\",\n",
        "    \"hey stranger\": \"Hello! How can I assist you today?\",\n",
        "    \"how's everything\": \"Everything is going well. How may I help you?\",\n",
        "    \"nice to see you\": \"Nice to see you too! How can I assist you today?\",\n",
        "    \"hey mate\": \"Hey! What can I do for you today?\",\n",
        "    \"how's your day\": \"My day is going well. How can I assist you?\",\n",
        "    \"pleased to meet you\": \"Pleased to meet you too! How can I assist you?\",\n",
        "    \"what's the latest\": \"Not much, just here to assist you!\",\n",
        "    \"hey friend\": \"Hello! How can I assist you today?\",\n",
        "    \"how's life\": \"Life is good. How may I assist you?\",\n",
        "    \"what's going on buddy\": \"Not much, just here to assist you!\",\n",
        "    \"hiya\": \"Hi there! How can I help you today?\",\n",
        "    \"how are things\": \"Things are going well. How can I assist you?\",\n",
        "    \"what's happening mate\": \"Not much, just here to assist you!\",\n",
        "    \"hey pal\": \"Hey! What can I do for you today?\",\n",
        "    \"how's your day going\": \"My day is going well. How can I assist you?\",\n",
        "    \"good to see you again\": \"Good to see you too! How may I assist you?\",\n",
        "    \"what's new buddy\": \"Not much, just here to assist you!\",\n",
        "    \"hey there friend\": \"Hello! How can I assist you today?\",\n",
        "    \"how's your day been\": \"My day has been good. How can I assist you?\",\n",
        "    \"nice to meet you too\": \"Nice to meet you too! How can I assist you today?\",\n",
        "    \"hey dude\": \"Hey! What can I do for you today?\",\n",
        "    \"how's everything going\": \"Everything is going well. How can I assist you?\",\n",
        "    \"what's happening friend\": \"Not much, just here to assist you!\",\n",
        "    \"hey amigo\": \"Hey! What can I do for you today?\",\n",
        "    \"how's your day so far\": \"My day is going well. How can I assist you?\",\n",
        "    \"good to see you once again\": \"Good to see you too! How may I assist you?\",\n",
        "    \"what's new pal\": \"Not much, just here to assist you!\",\n",
        "    \"hey there mate\": \"Hello! How can I assist you today?\",\n",
        "    \"how's your day treating you\": \"My day is treating me well. How can I assist you?\",\n",
        "    \"nice to meet you once more\": \"Nice to meet you too! How can I assist you today?\",\n",
        "    \"thank you\": \"You're welcome!\",\n",
        "    \"thanks\": \"You're welcome!\",\n",
        "    \"goodbye\": \"Goodbye!\",\n",
        "    \"bye\": \"Goodbye!\",\n",
        "    \"sorry\": \"No problem, I understand!\",\n",
        "    \"help\": \"Of course! What do you need help with?\",\n",
        "    \"yes\": \"Yes, I can help you with that!\",\n",
        "    \"no\": \"Alright, let me know if you need any assistance!\",\n",
        "    \"tell me a joke\": \"sure, here's a joke: Why don't scientists trust atoms? Because they make up everything!\",\n",
        "    \"great\": \"That's fantastic!\",\n",
        "    \"awesome\": \"That's great to hear!\",\n",
        "    \"good to know\": \"I'm glad you found that helpful!\",\n",
        "    \"you're amazing\": \"Thank you! I'm here to assist you!\",\n",
        "    \"you're the best\": \"Thank you! I'm here to help!\",\n",
        "    \"can you help me\": \"Absolutely! What do you need assistance with?\",\n",
        "    \"you're funny\": \"I try my best to bring a smile!\",\n",
        "    \"you're cool\": \"Thank you! I'm here to assist you!\",\n",
        "    \"you're awesome\": \"Thank you! I'm here to help!\",\n",
        "    \"that's cool\": \"I'm glad you think so!\",\n",
        "    \"that's interesting\": \"I find that fascinating too!\",\n",
        "    \"well done\": \"Thank you! I aim to provide helpful responses!\",\n",
        "    \"you're clever\": \"Thank you! I'm here to assist you!\",\n",
        "    \"good job\": \"Thank you! I'm here to help!\",\n",
        "    \"that's helpful\": \"I'm glad I could be of assistance!\",\n",
        "    \"you're smart\": \"Thank you! I'm here to assist you!\",\n",
        "    \"you're knowledgeable\": \"Thank you! I'm here to help!\",\n",
        "    \"you're reliable\": \"Thank you! I'm here to assist you!\",\n",
        "    \"you're dependable\": \"Thank you! I'm here to help!\",\n",
        "    \"that's nice\": \"I'm glad you think so!\",\n",
        "    \"you're great\": \"Thank you! I'm here to assist you!\",\n",
        "    \"you're wonderful\": \"Thank you! I'm here to help!\",\n",
        "    \"that's impressive\": \"I'm glad you find it impressive!\",\n",
        "    \"you're resourceful\": \"Thank you! I'm here to assist you!\",\n",
        "    \"you're helpful\": \"Thank you! I'm here to help!\",\n",
        "    \"you're supportive\": \"Thank you! I'm here to assist you!\",\n",
        "    \"you're encouraging\": \"Thank you! I'm here to help!\",\n",
        "    \"that's awesome\": \"I'm glad you think so!\",\n",
        "    \"you're fantastic\": \"Thank you! I'm here to assist you!\",\n",
        "    \"that's great\": \"I'm glad you find it great!\",\n",
        "    \"you're incredible\": \"Thank you! I'm here to assist you!\",\n",
        "    \"you're outstanding\": \"Thank you! I'm here to help!\",\n",
        "    \"that's wonderful\": \"I'm glad you think so!\",\n",
        "    \"you're remarkable\": \"Thank you! I'm here to assist you!\",\n",
        "    \"you're impressive\": \"Thank you! I'm here to help!\",\n",
        "    \"that's excellent\": \"I'm glad you find it excellent!\",\n",
        "    \"you're extraordinary\": \"Thank you! I'm here to assist you!\",\n",
        "    \"you're exceptional\": \"Thank you! I'm here to help!\",\n",
        "    \"that's remarkable\": \"I'm glad you think so!\",\n",
        "    \"that's fantastic\": \"I'm glad you find it fantastic!\",\n",
        "    \"that's brilliant\": \"I'm glad you think so!\",\n",
        "    \"you're the greatest\": \"Thank you! I'm here to assist you!\",\n",
        "    \"you're the coolest\": \"Thank you! I'm here to assist you!\",\n",
        "    \"you're the most helpful\": \"Thank you! I'm here to help!\",\n",
        "    \"that's amazing\": \"I'm glad you think so!\",\n",
        "    \"you're the most knowledgeable\": \"Thank you! I'm here to assist you!\",\n",
        "    \"you're the most reliable\": \"Thank you! I'm here to help!\",\n",
        "    \"you're the most dependable\": \"Thank you! I'm here to assist you!\",\n",
        "    \"you're the smartest\": \"Thank you! I'm here to help!\",\n",
        "    \"you're the most clever\": \"Thank you! I'm here to assist you!\",\n",
        "    \"you're the most resourceful\": \"Thank you! I'm here to help!\",\n",
        "    \"you're the most supportive\": \"Thank you! I'm here to assist you!\",\n",
        "    \"you're the most encouraging\": \"Thank you! I'm here to help!\",\n",
        "    \"you're the most fantastic\": \"Thank you! I'm here to assist you!\",\n",
        "    \"you're the most incredible\": \"Thank you! I'm here to help!\",\n",
        "    \"you're the most wonderful\": \"Thank you! I'm here to assist you!\",\n",
        "    \"nevermind\": \"I'm glad I could be of assistance!\"\n",
        "    }"
      ],
      "metadata": {
        "id": "C98JORkzPyEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# Disable transformers' logging\n",
        "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
        "\n",
        "# Load the fine-tuned model and tokenizer\n",
        "model = GPT2LMHeadModel.from_pretrained('./output_model')  # Path to the fine-tuned model's directory\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "tokenizer.pad_token = tokenizer.eos_token  # Set pad_token_id to the end of sentence token (eos_token_id)\n",
        "\n",
        "# Set the model to evaluate mode\n",
        "model.eval()\n",
        "\n",
        "# Move the model to the appropriate device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Function to generate model responses\n",
        "def generate_response(prompt):\n",
        "    prompt = prompt.lower()\n",
        "\n",
        "    # Check if prompt matches a greeting\n",
        "    for greeting in greetings:\n",
        "        if greeting == prompt:\n",
        "            return greetings[greeting]\n",
        "\n",
        "    # Check if the prompt is empty or contains only one word\n",
        "    if len(prompt.strip().split()) <= 1:\n",
        "        return \"I'm sorry, I couldn't generate a response. Kindly rephrase your query so I am able to understand better.\"\n",
        "\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors='pt', padding=True)\n",
        "\n",
        "    # Move the input tensor to the same device as the model\n",
        "    input_ids = input_ids.to(device)\n",
        "\n",
        "    attention_mask = input_ids.ne(tokenizer.pad_token_id)\n",
        "    output = model.generate(input_ids, attention_mask=attention_mask, max_length=150, num_return_sequences=1)\n",
        "\n",
        "    responses = []\n",
        "    for generated in output:\n",
        "        response = tokenizer.decode(generated, skip_special_tokens=True)\n",
        "        responses.append(response)\n",
        "\n",
        "    try:\n",
        "        if len(responses) > 0:\n",
        "            lines = responses[0].split('\\n')\n",
        "            lines2 = lines[0].split(',\"')\n",
        "            answer_line = lines2[1].replace('\"', \"\")\n",
        "            return answer_line\n",
        "    except IndexError:\n",
        "        pass\n",
        "\n",
        "    return \"I'm sorry, I couldn't generate a response. Kindly rephrase your query so I am able to understand better.\"\n"
      ],
      "metadata": {
        "id": "aak42ajJP026"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import jellyfish\n",
        "\n",
        "def jaccard_similarity(question, answer):\n",
        "    set_question = set(question.lower().split())\n",
        "    set_answer = set(answer.lower().split())\n",
        "    intersection = len(set_question.intersection(set_answer))\n",
        "    union = len(set_question) + len(set_answer) - intersection\n",
        "    similarity = intersection / union\n",
        "    return similarity\n",
        "\n",
        "# Read test dataset\n",
        "test_data = []\n",
        "with open('test_data_final.csv', 'r') as file:\n",
        "    reader = csv.reader(file)\n",
        "    for row in reader:\n",
        "        test_data.append(row)\n",
        "\n",
        "# Skip the first row containing column headers\n",
        "test_data = test_data[1:]\n",
        "\n",
        "# Prepare test dataset\n",
        "test_questions = []\n",
        "test_answers = []\n",
        "\n",
        "for row in test_data:\n",
        "    test_questions.append(row[0])\n",
        "    test_answers.append(row[1])\n",
        "\n",
        "# Generate responses\n",
        "generated_answers = []\n",
        "for question in test_questions:\n",
        "    generated_answers.append(generate_response(question))\n",
        "\n",
        "print(\"Total number of records:\", len(test_questions))\n",
        "\n",
        "# Calculate similarity metrics\n",
        "cosine_similarities = []\n",
        "jaccard_similarities = []\n",
        "levenshtein_distances = []\n",
        "\n",
        "for i in range(len(test_answers)):\n",
        "    answer = test_answers[i]\n",
        "    generated_answer = generated_answers[i]\n",
        "\n",
        "    # Calculate cosine similarity\n",
        "    tfidf_vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = tfidf_vectorizer.fit_transform([answer, generated_answer])\n",
        "    cosine_similarity_score = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])[0][0]\n",
        "    cosine_similarities.append(cosine_similarity_score)\n",
        "\n",
        "    # Calculate Jaccard similarity\n",
        "    jaccard_similarity_score = jaccard_similarity(answer, generated_answer)\n",
        "    jaccard_similarities.append(jaccard_similarity_score)\n",
        "\n",
        "# Calculate accuracy based on similarity thresholds\n",
        "cosine_threshold = 0.5\n",
        "jaccard_threshold = 0.5\n",
        "\n",
        "cosine_matches = sum(score >= cosine_threshold for score in cosine_similarities)\n",
        "jaccard_matches = sum(score >= jaccard_threshold for score in jaccard_similarities)\n",
        "\n",
        "accuracy_cosine = cosine_matches / len(test_data)\n",
        "accuracy_jaccard = jaccard_matches / len(test_data)\n",
        "\n",
        "# Print the evaluation scores\n",
        "print(f\"Cosine Similarity: {accuracy_cosine:.4f}\")\n",
        "print(f\"Jaccard Similarity: {accuracy_jaccard:.4f}\")"
      ],
      "metadata": {
        "id": "gSyV6HmLP3gQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot similarity scores\n",
        "plt.hist(cosine_similarities, bins=20, alpha=0.7, label='Cosine Similarity')\n",
        "plt.hist(jaccard_similarities, bins=20, alpha=0.7, label='Jaccard Similarity')\n",
        "\n",
        "plt.xlabel('Similarity Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Similarity Scores')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "H5AKtNjNP6Gq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create a scatter plot\n",
        "plt.scatter(cosine_similarities, jaccard_similarities, alpha=0.5)\n",
        "plt.xlabel('Cosine Similarity')\n",
        "plt.ylabel('Jaccard Similarity')\n",
        "plt.title('Cosine Similarity vs Jaccard Similarity')\n",
        "\n",
        "# Add a regression line\n",
        "coefficients = np.polyfit(cosine_similarities, jaccard_similarities, 1)\n",
        "polynomial = np.poly1d(coefficients)\n",
        "x_values = np.linspace(0, 1, 100)\n",
        "plt.plot(x_values, polynomial(x_values), color='red', label='Regression Line')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CSLw-eJsP-6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dataframe\n",
        "df = pd.DataFrame({'Question': test_questions,\n",
        "                   'Predicted Answer': generated_answers,\n",
        "                   'True Answer': test_answers})\n",
        "\n",
        "# Save the output to CSV for analysis\n",
        "df.to_csv('output.csv', index=False)"
      ],
      "metadata": {
        "id": "3lUgxA63QBXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chatbot loop\n",
        "while True:\n",
        "    user_input = input('User: ')\n",
        "    if user_input == \"Bye\":\n",
        "        print('Chatbot: Goodbye')\n",
        "        break\n",
        "    else:\n",
        "        response = generate_response(user_input)\n",
        "        print('Chatbot:', response)\n",
        "\n",
        "#What's the legal age of getting a G1 and G2 driver's license in Ontario?\n",
        "#I want answers to some traffic questions."
      ],
      "metadata": {
        "id": "xgDWmqYJQFdl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}